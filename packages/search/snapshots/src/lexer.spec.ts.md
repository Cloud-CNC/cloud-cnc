# Snapshot report for `src/lexer.spec.ts`

The actual snapshot is saved in `lexer.spec.ts.snap`.

Generated by [AVA](https://avajs.dev).

## Tokenize AND

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 3,
          endLine: 1,
          endOffset: 2,
          image: 'AND',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [
              {
                CATEGORIES: [],
                PATTERN: /NOT_APPLICABLE/,
                categoryMatches: [
                  5,
                  6,
                ],
                categoryMatchesMap: {
                  5: true,
                  6: true,
                },
                isParent: true,
                name: '[double operand boolean operator]',
                tokenTypeIdx: 4,
              },
            ],
            PATTERN: /AND/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'AND',
            tokenTypeIdx: 5,
          },
          tokenTypeIdx: 5,
        },
      ],
    }

## Tokenize OR

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 2,
          endLine: 1,
          endOffset: 1,
          image: 'OR',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [
              {
                CATEGORIES: [],
                PATTERN: /NOT_APPLICABLE/,
                categoryMatches: [
                  5,
                  6,
                ],
                categoryMatchesMap: {
                  5: true,
                  6: true,
                },
                isParent: true,
                name: '[double operand boolean operator]',
                tokenTypeIdx: 4,
              },
            ],
            PATTERN: /OR/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'OR',
            tokenTypeIdx: 6,
          },
          tokenTypeIdx: 6,
        },
      ],
    }

## Tokenize NOT

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 3,
          endLine: 1,
          endOffset: 2,
          image: 'NOT',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /NOT/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'NOT',
            tokenTypeIdx: 7,
          },
          tokenTypeIdx: 7,
        },
      ],
    }

## Tokenize opening parenthesis

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: '(',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /\(/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '(',
            tokenTypeIdx: 8,
          },
          tokenTypeIdx: 8,
        },
      ],
    }

## Tokenize closing parenthesis

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: ')',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /\)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: ')',
            tokenTypeIdx: 9,
          },
          tokenTypeIdx: 9,
        },
      ],
    }

## Tokenize single-quoted literal string

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 6,
          endLine: 1,
          endOffset: 5,
          image: '\'much\'',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /(['"])(?:.+?\1)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '[literal string]',
            tokenTypeIdx: 10,
          },
          tokenTypeIdx: 10,
        },
      ],
    }

## Tokenize single-quoted literal string containing a double-quote

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 7,
          endLine: 1,
          endOffset: 6,
          image: '\'mu"ch\'',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /(['"])(?:.+?\1)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '[literal string]',
            tokenTypeIdx: 10,
          },
          tokenTypeIdx: 10,
        },
      ],
    }

## Tokenize double-quoted literal string

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 6,
          endLine: 1,
          endOffset: 5,
          image: '"much"',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /(['"])(?:.+?\1)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '[literal string]',
            tokenTypeIdx: 10,
          },
          tokenTypeIdx: 10,
        },
      ],
    }

## Tokenize double-quoted literal string containing a single-quote

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 7,
          endLine: 1,
          endOffset: 6,
          image: '"mu\'ch"',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /(['"])(?:.+?\1)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '[literal string]',
            tokenTypeIdx: 10,
          },
          tokenTypeIdx: 10,
        },
      ],
    }

## Tokenize literal string containing only a keyword

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 4,
          endLine: 1,
          endOffset: 3,
          image: '"OR"',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /(['"])(?:.+?\1)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '[literal string]',
            tokenTypeIdx: 10,
          },
          tokenTypeIdx: 10,
        },
      ],
    }

## Tokenize fuzzy string

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 16,
          endLine: 1,
          endOffset: 15,
          image: 'not so literally',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            LINE_BREAKS: true,
            PATTERN: {
              exec: Function exec {},
            },
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: '[fuzzy string]',
            tokenTypeIdx: 11,
          },
          tokenTypeIdx: 11,
        },
      ],
    }
