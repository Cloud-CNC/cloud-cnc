# Snapshot report for `src/lexer.spec.ts`

The actual snapshot is saved in `lexer.spec.ts.snap`.

Generated by [AVA](https://avajs.dev).

## Tokenize AND

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 3,
          endLine: 1,
          endOffset: 2,
          image: 'AND',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [
              {
                CATEGORIES: [],
                PATTERN: /NOT_APPLICABLE/,
                categoryMatches: [
                  6,
                  7,
                ],
                categoryMatchesMap: {
                  6: true,
                  7: true,
                },
                isParent: true,
                name: 'DoubleOperandBooleanOperator',
                tokenTypeIdx: 5,
              },
            ],
            PATTERN: /AND/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'And',
            tokenTypeIdx: 6,
          },
          tokenTypeIdx: 6,
        },
      ],
    }

## Tokenize OR

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 2,
          endLine: 1,
          endOffset: 1,
          image: 'OR',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [
              {
                CATEGORIES: [],
                PATTERN: /NOT_APPLICABLE/,
                categoryMatches: [
                  6,
                  7,
                ],
                categoryMatchesMap: {
                  6: true,
                  7: true,
                },
                isParent: true,
                name: 'DoubleOperandBooleanOperator',
                tokenTypeIdx: 5,
              },
            ],
            PATTERN: /OR/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'Or',
            tokenTypeIdx: 7,
          },
          tokenTypeIdx: 7,
        },
      ],
    }

## Tokenize NOT

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 3,
          endLine: 1,
          endOffset: 2,
          image: 'NOT',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /NOT/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'Not',
            tokenTypeIdx: 8,
          },
          tokenTypeIdx: 8,
        },
      ],
    }

## Tokenize opening parenthesis

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: '(',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /\(/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'OpeningParenthesis',
            tokenTypeIdx: 9,
          },
          tokenTypeIdx: 9,
        },
      ],
    }

## Tokenize closing parenthesis

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: ')',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /\)/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'ClosingParenthesis',
            tokenTypeIdx: 10,
          },
          tokenTypeIdx: 10,
        },
      ],
    }

## Tokenize single quote

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: '\'',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /['"]/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'Quote',
            tokenTypeIdx: 11,
          },
          tokenTypeIdx: 11,
        },
      ],
    }

## Tokenize double quote

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: '"',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /['"]/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'Quote',
            tokenTypeIdx: 11,
          },
          tokenTypeIdx: 11,
        },
      ],
    }

## Tokenize literal string

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 1,
          endLine: 1,
          endOffset: 0,
          image: '"',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /['"]/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'Quote',
            tokenTypeIdx: 11,
          },
          tokenTypeIdx: 11,
        },
        {
          endColumn: 18,
          endLine: 1,
          endOffset: 17,
          image: 'much OR literally',
          startColumn: 2,
          startLine: 1,
          startOffset: 1,
          tokenType: {
            CATEGORIES: [],
            LINE_BREAKS: true,
            PATTERN: {
              exec: Function exec {},
            },
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'String',
            tokenTypeIdx: 12,
          },
          tokenTypeIdx: 12,
        },
        {
          endColumn: 19,
          endLine: 1,
          endOffset: 18,
          image: '"',
          startColumn: 19,
          startLine: 1,
          startOffset: 18,
          tokenType: {
            CATEGORIES: [],
            PATTERN: /['"]/,
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'Quote',
            tokenTypeIdx: 11,
          },
          tokenTypeIdx: 11,
        },
      ],
    }

## Tokenize non-literal string

> Snapshot 1

    {
      errors: [],
      groups: {},
      tokens: [
        {
          endColumn: 16,
          endLine: 1,
          endOffset: 15,
          image: 'not so literally',
          startColumn: 1,
          startLine: 1,
          startOffset: 0,
          tokenType: {
            CATEGORIES: [],
            LINE_BREAKS: true,
            PATTERN: {
              exec: Function exec {},
            },
            categoryMatches: [],
            categoryMatchesMap: {},
            isParent: false,
            name: 'String',
            tokenTypeIdx: 12,
          },
          tokenTypeIdx: 12,
        },
      ],
    }
